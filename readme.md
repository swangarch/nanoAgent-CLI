# NanoAgent-CLI

### A minimalist CLI coding agent in < 100 lines of python code
---

With fewer than 100 lines of Python, this repo implements an AI agent from scratch, without using agent frameworks. It turns an LLM into a CLI-based coding AI agent.

Yes, it can do vibe coding.

The idea is to illustrate the principle as simple as possible, easy to understand, and still functional.

The agent is tested using the open-source model **MiniMax M2**, it accepts also all models with OpenAI API including local LLMs, and it can autonomously:
- Write web pages
- Create terminal-based games
- Execute shell commands
- Manipulate files
- And more

Some tests results are placed in /examples, they are all generated by nanoAgent-CLI.

## Background

This project is inspired by:

- **ReAct** (Reason + Act) paradigm
- The idea of **we can do anything with bash command.**
- The idea that as foundation models improve in reasoning, **complex agent frameworks become less necessary**, simple interaction loop is enough. 
- **Prompt engineering**. The project combines prompt and code. It uses carefully designed prompts, followed by checks, to constrain and guide the model's behavior.

## Core Ideas
- Minimalism first: fewer abstractions, more clarity
- Transparent behavior: you see and prove every command before execution
- This agent is implemented in a **ReAct** paradigm loop:
    - User send task
    - Model reasons about the task
    - Model proposes a bash command
    - User approves or rejects execution
    - System feeds execution result back to the model
    - Loop continues until <TASK_DONE> is emitted


## Getting Started

### Requirements
- Python 3.8+
- Linux / macOS (Windows users should use WSL or a virtual machine)
- Bash shell
- Python Dependencies

```python
pip install openai python-dotenv
```

Or use the provided setup script and virtual environment:
```bash
bash setup.sh
source venv/bin/activate
```

### Configuration
Create a .env file in the project root:

#### Examples
Using remote model (e.g. OpenAI)
```
BASE_URL="https://api.openai.com/v1"
API_KEY="sk-xxxx"
MODEL="gpt-4o-mini"
```

Using local model (e.g. Ollama)
```
BASE_URL="http://localhost:11434/v1"
API_KEY="ollama"
MODEL="qwen2.5:7b"
```
### Run agent

```bash
python nanoAgent-CLI.py
```

You will see an interactive CLI like:
```
[Agent]: How can I help you?
[User]: (wait user's input)
```
Now you can ask agent to do things. 

eg:
```
[User]:  Generate me a snake game in terminal, using python, put it into snake folder.
```

or 
```
[User]:  Write me a portfolio website to showcase my photos, put it into site folder.
```

or 
```
[User]:  Organise the files for me, put the files related to calculator to where it should go.
```

When the model proposes a command, you must manually approve it:
```
[[Execute task] -> (ls -la ...) y/n? ] >
```
If you do not enter y, the execution will be canceled and the model will be notified.

The model will do the task step-by-step, it will continue to output command, until the task is done, you can break the task with Ctrl+C,
and give model further instruction.

### How It Works
- The model outputs bash commands inside fenced blocks:
- Using system prompt to restrict model behavior
- Commands are extracted via regex
- Only **one bash block is allowed per response**
- Execution results are fed back to the model as system feedback,
- The task ends when the model outputs: <TASK_DONE>

---

## Why NanoAgent?

Because to understand LLM Agent:

- You don’t need LangChain
- You don’t need function calling
- You don’t need 10 layers of abstraction
- You don't need blackbox tools

In the react paradigm, you just need: **A main loop, a sub loop, a model, and a shell.**
And it works.

---

## Limitations

- No sandboxing
- No permission system
- No tool schema validation
- Performance heavily depends on the base model’s reasoning ability
- Different models may behave **very differently**，some model doesn't strictly follow system prompt

## Security Notice

**Caution**

Allowing an LLM to generate and execute bash commands is **inherently risky**.

- Always review commands before execution
- Never run this agent with elevated privileges
- Do not expose it to untrusted users
- Do not use it on production systems

This project is for **educational and experimental purposes**.

---

## License

This project is under MIT License.